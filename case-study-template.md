# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: *объем потребления оперативной памяти при обработке файла `data_large` в течение работы программы. Использовались файлы 100_000 строк - начальный и конечный замперы, 40_000 - промежуточные.

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за *время, которое у вас получилось*

Вот как я построил `feedback_loop`: *как вы построили feedback_loop*
memory-profiler
ruby-prof call_grind
ruby-prof call_stack

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался *инструментами, которыми вы воспользовались*

Вот какие проблемы удалось найти и решить

### Ваша находка №0
Перевод программы на потоковый подход (File.foreach вместо File.read) значимо на объем памяти и время выполнения не повлиял

Стартовое значение метрики (40_000)
# MEMORY USAGE: 316 MB
# Finish in 16.95

### Ваша находка №1
memory-profiler:
MEMORY USAGE: 5425 MB
Total allocated: 6.70 GB (2039801 objects)
allocated memory by location: 
4.59 GB: `sessions = sessions + [parse_session(line)] if cols[0] == 'session'`
1.55 GB: user_sessions = sessions.select { |session| session['user_id'] == user['id'] }

allocated objects by location:
611814 - { 'dates' => user.sessions.map{|s| s['date']}.map {|d| Date.parse(d)}.sort.reverse.map { |d| d.iso8601 } }

Allocated String Report:
144564  " " - 154
107718  "session" - 61

stackprof - менее информативен, далее не пользуемся
ruby-prof flat - менее информативен, далее не пользуемся
ruby-prof graph - неплохой, пользуемся как вспомогательным
ruby-prof call_stack - отличный в плане визуала, пользуемся как вторым основным, graph не нужен
2 точки роста:
54% - Object#collect_stats_from_users
  -> 26% - Date#parse
42% - Foreach#each
  -> 14% - #parse_session
ruby-prof call_grind - просто лучший, хотя дольше вызывать, пользуем только его и memory-profiler

- как вы решили её оптимизировать
Array#<< вместо Array#+ в `sessions = sessions + [parse_session(line)] if cols[0] == 'session'`

- как изменилась метрика: уменьшилась в 2 раза
# MEMORY USAGE: 179 MB

- как изменился отчёт профилировщика
memory-profiler:
1.6MB: `sessions = sessions + [parse_session(line)] if cols[0] == 'session'`

### Ваша находка №2
- какой отчёт показал главную точку роста
memory-profiler:
Total allocated: 1.96 GB (1959801 objects)
1.66 GB: user_sessions = sessions.select { |session| session['user_id'] == user['id'] }
allocated memory by class
-----------------------------------
   1.69 GB  Array
  66.92 MB  String

call_stack:
56% - Object#collect_stats_from_users
  -> Array#each
    -> Array#map
      -> Data#parse

- как вы решили её оптимизировать
Снова идем за memory-profiler: в Array#each с #select меняем Array#+ на Array#<<. Эффект однако небоьшой, проблема - 
в неприлично разбухающем количестве select-массивов при итерации юзеров. Поэтому заменил их промежуточным хэшем с одним проходом по sessions, из которого потом удобно формировать хэш юзеров.

- как изменилась метрика
# MEMORY USAGE: 65 MB: в 3 раза
# Finish in 0.38

- как изменился отчёт профилировщика
1.18 MB:)
allocated memory by class
-----------------------------------
  67.16 MB  String
  28.59 MB  Hash
  26.59 MB  Array

### Ваша находка №3
- какой отчёт показал главную точку роста
Возвращаемся к отчетам ruby-prof, который теперь более показательные чем memory-profiler
memory-profiler:
48.05 MB - #map
56% - Object#collect_stats_from_users
  -> Array#each
    -> Array#map
      -> Date#parse
call_stack:
Array#map [67551 calls, 67553 total]

Слишком много map
- как вы решили её оптимизировать
Убираем лишние maps при вызовах Object#collect_stats_from_users, также уберем Date.parse

- как изменилась метрика: меньше, чем хотелось бы
MEMORY USAGE: 53 MB
Finish in 0.25

- как изменился отчёт профилировщика
18% - Object#collect_stats_from_users
Array#map [6141 calls, 12284 total]

### Ваша находка №4
- какой отчёт показал главную точку роста
- как вы решили её оптимизировать
- как изменилась метрика
- как изменился отчёт профилировщика

### Ваша находка №6
- какой отчёт показал главную точку роста
- как вы решили её оптимизировать
- как изменилась метрика
- как изменился отчёт профилировщика

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с *того, что у вас было в начале, до того, что получилось в конце* и уложиться в заданный бюджет.

*Какими ещё результами можете поделиться*

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы *о performance-тестах, которые вы написали*
